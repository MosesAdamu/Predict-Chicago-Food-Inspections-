{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Bq3QG9AFOKpL",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0925c669622f603e4025ce4d926d8384",
     "grade": false,
     "grade_id": "cell-f2b2468124042cfe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "_BloomTech Data Science, Unit 2_\n",
    "\n",
    "---\n",
    "\n",
    "👇 **Do not change the code in this cell.** If you're working in Google Colab, you can run this cell to install `category_encoders` and `pdpbox`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "2LNg6SMHOKpV",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6e84593629f1e735cc6423e463199480",
     "grade": false,
     "grade_id": "cell-656c869f2d287493",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import sys\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    !pip install category_encoders\n",
    "    !pip install matplotlib==3.7.1\n",
    "    !pip install pdpbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install category_encoders\n",
    "pip install matplotlib==3.7.1\n",
    "pip install pdpbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "7GauJXp-OKpY",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "be6f7489d8b09d515eed676f06ac2d3b",
     "grade": false,
     "grade_id": "cell-dbdc2fe26ba31738",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Sprint Challenge: Predict Chicago Food Inspections 🍕\n",
    "\n",
    "In this challenge, you'll use data from the [Chicago Department of Public Health](https://www.chicago.gov/city/en/depts/cdph/provdrs/healthy_restaurants/svcs/food-protection-services.html) to build a model to predict whether a food establishment passed inspection or not.\n",
    "\n",
    "The purpose of this model is to help inspectors use their time more efficiently by identifying establishments that will likely fail inspection. In other words, this model should be able to predict whether an establishment will fail inspection *before* the inspector arrives at the establishment.\n",
    "\n",
    "# Directions\n",
    "\n",
    "This notebook contains 12 tasks, which cover the material we've learned in this sprint. Here's a summary:\n",
    "\n",
    "- **Task 1:** Importing data.\n",
    "- **Task 2:** Identifying data leakage.\n",
    "- **Task 3:** Writing a wrangle function.\n",
    "- **Task 4:** Splitting data into a feature matrix and target vector.\n",
    "- **Task 5:** Splitting data into training and validation sets.\n",
    "- **Task 6:** Establishing baseline accuracy.\n",
    "- **Task 7:** Building model with bagging predictor.\n",
    "- **Task 8:** Building model with boosting predictor.\n",
    "- **Task 9 (`stretch goal`):** Plotting ROC curves.\n",
    "- **Task 10:** Generating classification report.\n",
    "- **Task 11:** Calculating permutation importances.\n",
    "- **Task 12 (`stretch goal`):** Creating PDP interaction plot.\n",
    "\n",
    "For each task you should do the following:\n",
    "\n",
    "- Read the task instructions.\n",
    "- Write your code in the cell below the task. Delete the `raise NotImplementedError` before your start.\n",
    "- Run the testing cell below the task. If you get an error, read the error message and re-evaluate your code.\n",
    "\n",
    "**You should limit your code to the following libraries:**\n",
    "\n",
    "- `category_encoders`\n",
    "- `numpy`\n",
    "- `matplotlib`\n",
    "- `pandas`\n",
    "- `pdpbox`\n",
    "- `sklearn`\n",
    "- `xgboost`\n",
    "\n",
    "**A word of warning:** The virtual machine that will check your answers is small. So, where applicable, don't use huge values for `n_estimators` (`>100`) or `n_jobs` (keep at `-1`).\n",
    "\n",
    "If you'd like to import all your libraries at the start of your notebook, you can do so in the code block below 👇"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "AZWqBWcVOKpc",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "313c53b0dc59a11bb7bfaefbf995fe2c",
     "grade": false,
     "grade_id": "cell-44be413734e30691",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "#data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# encoders\n",
    "from category_encoders import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "#pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Bagged Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Boosted Models\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Permutation Importance\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# for displaying images and html\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "3HtzhlYaOKpf",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "48dd82293df0d9af1aa7efac7f7468fa",
     "grade": false,
     "grade_id": "cell-602d346d44303e87",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# I. Wrangle Data\n",
    "\n",
    "**Task 1:** Change the code below to import your dataset. Be sure to examine the columns carefully and determine if one of them should be set as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 656
    },
    "deletable": false,
    "id": "jA415NcKOKph",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dafd956974169191567e3544c18186a5",
     "grade": false,
     "grade_id": "cell-8b9246d8d97a80ff",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "20fcd4a5-15c7-451a-843d-75426256da6f"
   },
   "outputs": [],
   "source": [
    "'''T1. Import data file.'''\n",
    "url = 'https://drive.google.com/uc?export=download&id=1aUnQ4AJK4UtW8JL9zPyYUMtkjIgQpqKT'\n",
    "df = pd.read_csv(url, parse_dates=['Inspection Date']).set_index('Inspection Date')\n",
    "# YOUR CODE HERE\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "7DwyMSF1OKph",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "493ede874f1e2c163a74021a41d8775d",
     "grade": false,
     "grade_id": "cell-1b2eb047117d89ab",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Task 1 Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "_eKehbobOKpi",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0d68298cfa23877cd61b8ba487c19dc6",
     "grade": true,
     "grade_id": "cell-e9593d4f4ed7a9bb",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''T1 Test'''\n",
    "assert isinstance(df, pd.DataFrame), 'Have you created a DataFrame named `df`?'\n",
    "assert len(df) == 51916"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "eWeiKi9OOKpj",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1ee62609b3bf18520406b3837f7843a6",
     "grade": false,
     "grade_id": "cell-9e90dce33ddd0506",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Task 2:** Given that this model is supposed to generate predictions *before* an inspection is conducted, identify the numerical feature that is an example of **data leakage.** Assign the column name to the variable `'leaky_col'`.\n",
    "\n",
    "**Remember:** Leakage is when your feature matrix includes columns that will not be available to your model at the time it make predictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "46Ezych5OKpk",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "27b878765c52a092c3c56791dde91d5d",
     "grade": false,
     "grade_id": "cell-ef24afc9168ad64f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''T2. Identify data leakage column.'''\n",
    "leaky_col = 'Serious Violations Found'\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "iPt91p1nOKpl",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9874ad6b513dd2c2e409aa1d6610a65e",
     "grade": false,
     "grade_id": "cell-378fd448d54e6fc0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Task 2 Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "WJ_PtA11OKpm",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5a57c6a47e502a421524daf29beb7941",
     "grade": true,
     "grade_id": "cell-8429f30efb2a7bf7",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''T2 Test'''\n",
    "# This is a hidden test.\n",
    "# You'll see the result when you submit to Canvas.\n",
    "assert isinstance(leaky_col, str), '`leaky_col` should be type `str`.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "CgRAuXgXOKpm",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b17eb5d6c465729f58b1739a11ea5b96",
     "grade": false,
     "grade_id": "cell-2f7298cea62c493e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Task 3:** Add to the `wrangle` function below so that it does the following:\n",
    "\n",
    "- Removes the \"leaky\" column.\n",
    "- Removes high-cardinality categorical columns (more than `500` categories).\n",
    "- Removes categorical columns that have only one category.\n",
    "- Removes numerical columns that are unique identifiers for each observation, not features that would affect the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "H_LWV7VuOKpn",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "40e1745bb407a170e1dec8221d37fc3c",
     "grade": false,
     "grade_id": "cell-d6fc5ee398afff4f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''T3. Write wrangle function.'''\n",
    "def wrangle(df):\n",
    "    # Remove the \"leaky\" column\n",
    "    df = df.drop(columns=['Serious Violations Found'])\n",
    "\n",
    "    df = df.drop(columns= ['License #'])\n",
    "\n",
    "    # Remove high-cardinality categorical columns\n",
    "    high_cardinality_cols = [col for col in df.select_dtypes(include=['object']).columns if df[col].nunique() > 500]\n",
    "    df = df.drop(columns=high_cardinality_cols)\n",
    "\n",
    "    # Remove categorical columns with only one category\n",
    "    single_category_cols = [col for col in df.select_dtypes(include=['object']).columns if df[col].nunique() == 1]\n",
    "    df = df.drop(columns=single_category_cols)\n",
    "\n",
    "    # Remove numerical columns that are unique identifiers\n",
    "    unique_id_cols = [col for col in df.select_dtypes(include=['int64', 'float64']).columns if df[col].nunique() == len(df)]\n",
    "    df = df.drop(columns=unique_id_cols)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply the wrangle function to your DataFrame\n",
    "df = wrangle(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NoYhr4Zs3uW_",
    "outputId": "0bcd43a0-4b4b-4180-b17a-e83c99e0ce23"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "pekPgiEsOKpn",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "22afb4a381b73f41b02f83ca4a0102bd",
     "grade": false,
     "grade_id": "cell-7b5d539f39db8415",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Task 3 Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "aRidZF3SOKpo",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "05d5f964ad8d8bf468bd907abaa85213",
     "grade": true,
     "grade_id": "cell-49f495efb58bcd9f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''T3 Test'''\n",
    "assert df.select_dtypes('object').nunique().max() < 500, 'Have you dropped the high-cardinality columns?'\n",
    "assert df.select_dtypes('object').nunique().min() > 1, 'Have you dropped the column with only one category?'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "3eS7TozGOKpo",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f93a157b989f3327402d7b93a31bb595",
     "grade": false,
     "grade_id": "cell-aea953fa5337fc1f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# II. Split Data\n",
    "\n",
    "**Task 4:** Split the DataFrame `df` into the feature matrix `X` and the target vector `y`. Your target is `'Fail'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "oNESV5DTOKpp",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7bfd4151db9dd6615a624da2954138e8",
     "grade": false,
     "grade_id": "cell-b21b1c40f5478337",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''T4. Split feature matrix and target vector.'''\n",
    "target = 'Fail'\n",
    "# YOUR CODE HER\n",
    "y = df[target]\n",
    "X = df.drop(columns=['Fail'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "eUnz7sMFOKpq",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2f00ae85d10438328017da8b01b77354",
     "grade": false,
     "grade_id": "cell-d9a64e5a6bd2a37d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Task 4 Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Ak_UC17uOKpq",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "04db76e9023f0b61187af1e39513d377",
     "grade": true,
     "grade_id": "cell-a1d912e28c9f7522",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''T4 Test'''\n",
    "assert y.shape == (51916,), '`y` either has the wrong number of rows, or is two-dimentional.'\n",
    "assert len(X) == 51916, '`X` has the wrong number of rows.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "uZjJwUbHOKpy",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e719471298c6c418489a657a500b7d0e",
     "grade": false,
     "grade_id": "cell-b575fbda93b87f6a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Task 5:** Split your dataset into training and validation sets.\n",
    "\n",
    "- Your training set (`X_train`, `y_train`) should contain inspections conducted before 2017.\n",
    "- Your validation set (`X_val`, `y_val`) should contain inspections conducted during or after 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "UrgVdxPoOKpz",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f92b2b9f9460a17c987c23188e3c31b1",
     "grade": false,
     "grade_id": "cell-0bb47689fd4667ed",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''T5. Split dataset into training and validation sets.'''\n",
    "# YOUR CODE HERE\n",
    "cutoff = '2017'\n",
    "mask = X.index < cutoff\n",
    "X_train, y_train = X.loc[mask], y.loc[mask]\n",
    "X_val, y_val = X.loc[~mask], y.loc[~mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Q9qxnOFYOKp1",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "60e77b85e7db0d0cb2522b8caa399e77",
     "grade": false,
     "grade_id": "cell-8517b2d477256843",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Task 5 Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ooKPW0QdOKp2",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "56e9e6ef918d3a662decf3f6d67dfd01",
     "grade": true,
     "grade_id": "cell-52cf3ef1934a4278",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''T5 Test'''\n",
    "assert len(X_train) == len(y_train) == 41827, 'Your training set has the wrong number of observations.'\n",
    "assert len(X_val) == len(y_val) == 10089, 'Your validation set has the wrong number of observations.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "RvyxwLzxOKp3",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0641d242faca29af591ebea98bc88ed6",
     "grade": false,
     "grade_id": "cell-2e9a4c74f50ed0fc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# III. Establish Baseline\n",
    "\n",
    "**Task 6:** Establish the baseline accuracy score for this classification problem using your training set. Save the score to the variable `baseline_acc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "OMAyz5idOKp3",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b658c6901efe4fe564387be697265352",
     "grade": false,
     "grade_id": "cell-3d21cc97649be107",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "9d91bdbf-bf0a-4e15-8b50-88158cddc5b2"
   },
   "outputs": [],
   "source": [
    "'''T6. Establish baseline accuracy.'''\n",
    "# YOUR CODE HERE\n",
    "baseline_acc = y_train.value_counts(normalize=True).max()\n",
    "print('Baseline accuracy:', baseline_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "JSgYZq6nOKp3",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6098c9452685d029c07b96f5295b5c1d",
     "grade": false,
     "grade_id": "cell-56d5801c8831c15b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Task 6 Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "hZAVJVhkOKp4",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8527a8f2e79c09d69519059e56c54272",
     "grade": true,
     "grade_id": "cell-abdc4cbe95e9d1da",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''T6 Test'''\n",
    "assert isinstance(baseline_acc, float), '`baseline_acc` should be type float. Have you defined the variable?'\n",
    "assert 0.0 <= baseline_acc <= 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "UVVgYSXTOKp5",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8a0f7eab56c05e92a441333652ccf6cf",
     "grade": false,
     "grade_id": "cell-7d68939c4eced62c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# IV. Build Model\n",
    "\n",
    "In this section, you want to answer the question: Which ensemble method performs better with this data — bagging or boosting?\n",
    "\n",
    "**Task 7:** Build a model that includes a bagging predictor (`RandomForest`). Your predictor should be part of a pipeline named `model_bag` that includes any transformers that you think are necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "ppKnmmegOKp5",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "49a48b340c0ee7f9630c3ce57e4ca439",
     "grade": false,
     "grade_id": "cell-889285d53fdbe282",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''T7. Build model with bagging predictor.'''\n",
    "# YOUR CODE HERE\n",
    "model_bag = make_pipeline(\n",
    "    OrdinalEncoder(),\n",
    "    SimpleImputer(strategy='median'),\n",
    "    RandomForestClassifier(random_state=42, n_jobs=-1,n_estimators=75)\n",
    ")\n",
    "\n",
    "model_bag.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "avLzhm3DOKp6",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "81055fe5d87448fd8e4aff2ca4f10ea0",
     "grade": false,
     "grade_id": "cell-72dac6ede9a13038",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Tast 7 Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "g3gsw2lDOKp6",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "57725e1ca8a837d8fa761271f994ad44",
     "grade": true,
     "grade_id": "cell-cddc5d7d2170877b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''T7 Testing'''\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "assert isinstance(model_bag, Pipeline), '`model_bag` is the wrong data type. Have you assigned your pipeline to the correct variable name?'\n",
    "assert isinstance(model_bag[-1], RandomForestClassifier), 'Your predictor should be a `RandomForestClassifier`.'\n",
    "assert hasattr(model_bag[-1], 'feature_importances_'), 'Have you trained your model?'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "KNPw_fEtOKp9",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5e3c031075213c671f8f9b321585e9eb",
     "grade": false,
     "grade_id": "cell-d9750931390fe58f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Task 8:** Build a model that includes a boosting predictor (`GradientBoostingClassifier` from `sklearn` or `XGBClassifier` from `xgboost`). Your predictor should be part of a pipeline named `model_boost` that includes any transformers that you think are necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "Q7tUFaA6OKp_",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a30d11fa6b0d4e143f4572b0baf65afb",
     "grade": false,
     "grade_id": "cell-37f16b5811ae5223",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''T8. Build model with boosting predictor.'''\n",
    "# YOUR CODE HERE\n",
    "model_boost = make_pipeline(\n",
    "    OrdinalEncoder(),\n",
    "    SimpleImputer(strategy='mean'),\n",
    "    GradientBoostingClassifier(random_state=42, n_estimators=75)\n",
    ")\n",
    "\n",
    "model_boost.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "eH1usZhBOKqA",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "64d1c2ff5004fe02082dc204299e0e70",
     "grade": false,
     "grade_id": "cell-3699731f62fa5db3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Task 8 Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "hYlqizUGOKqB",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "35744289b60d1556e064bc09da544566",
     "grade": true,
     "grade_id": "cell-90deb42a1c052402",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''T8 Testing'''\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "assert isinstance(model_boost, Pipeline), '`model_boost` is the wrong data type. Have you assigned your pipeline to the correct variable name?'\n",
    "assert any([isinstance(model_boost[-1], XGBClassifier),\n",
    "            isinstance(model_boost[-1], GradientBoostingClassifier)]), 'Your predictor should be `XGBClassifier` or `GradientBoostingClassifier`.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "0gk9Rkw8OKqC",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ebed19854d947c07608d2cb6c356f7ec",
     "grade": false,
     "grade_id": "cell-dc041ac00c805cff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# V. Check Metrics\n",
    "\n",
    "Here are the accuracy scores for your two models. Did you beat the baseline? Which of your two models appears to perform better on your validation set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "W_uBXRibOKqC",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fc12491c98afa1dd0767422ce0a07b22",
     "grade": false,
     "grade_id": "cell-c0206a761fccab6c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "fd8ad715-3019-4ae9-8cdd-391ffb1c0a9c"
   },
   "outputs": [],
   "source": [
    "print('Bagging Model')\n",
    "print('Training accuracy:', model_bag.score(X_train, y_train))\n",
    "print('Validation accuracy:', model_bag.score(X_val, y_val))\n",
    "print()\n",
    "print('Boosting Model')\n",
    "print('Training accuracy:', model_boost.score(X_train, y_train))\n",
    "print('Validation accuracy:', model_boost.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "gHR-asVSOKqD",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "044f92b1e1321a290f39d2a3d4f756ed",
     "grade": false,
     "grade_id": "cell-17e8e5433e896bc5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Task 9 (`stretch_goal`):** Plot the ROC-curve for both of your models (you can plot them one-at-a-time, side-by-side, or in the same plot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "deletable": false,
    "id": "8avox9eLOKqQ",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e4a418ccf53481f58016cf1828e973da",
     "grade": false,
     "grade_id": "cell-769e4a780bb22283",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "f42cb544-802a-4169-a0ce-0a529611943b"
   },
   "outputs": [],
   "source": [
    "'''T9. Plot ROC-curve.'''\n",
    "# YOUR CODE HERE\n",
    "rf_probs = model_bag.predict_proba(X_val)[:, 1]\n",
    "gb_probs = model_boost.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Plot ROC curves\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_val, rf_probs)\n",
    "fpr_gb, tpr_gb, _ = roc_curve(y_val, gb_probs)\n",
    "\n",
    "roc_auc_rf = auc(fpr_rf, tpr_rf)\n",
    "roc_auc_gb = auc(fpr_gb, tpr_gb)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot ROC curve for Random Forest model\n",
    "plt.plot(fpr_rf, tpr_rf, color='darkorange', lw=2, label=f'Random Forest (AUC = {roc_auc_rf:.2f})')\n",
    "plt.plot(fpr_gb, tpr_gb, color='green', lw=2, label=f'Gradient Boosting (AUC = {roc_auc_gb:.2f})')\n",
    "\n",
    "# Plot ROC curve for a random classifier (diagonal line)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "DzDEC0_oOKqR",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c2a7559346e95bf6ecd31e90dcefd3be",
     "grade": false,
     "grade_id": "cell-1b8571c3a6a034f5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Task 10:** Choose one of your models based on your validation accuracy score or your ROC curves. Then create a classification report for that model using your validation data. Save the text of the report to the variable name `model_cr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "qRhMWY7iOKqR",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ef340cbc8ec53da648b929c0bab96ef",
     "grade": false,
     "grade_id": "cell-49891c4ce9bf5f37",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "5e24738a-fb4f-42e7-d423-643d2b454559"
   },
   "outputs": [],
   "source": [
    "'''T10. Generate classification report for one model.'''\n",
    "from sklearn.metrics import classification_report\n",
    "# YOUR CODE HER\n",
    "\n",
    "# Predict using the Random Forest model on the validation set\n",
    "gb_predictions = model_boost.predict(X_val)\n",
    "\n",
    "# Create a classification report\n",
    "model_cr = classification_report(y_val, gb_predictions)\n",
    "\n",
    "# Print or use the report as needed\n",
    "print(model_cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "sKZUVyk2OKqS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "103296abc9f51aa4b883c35c418275cc",
     "grade": false,
     "grade_id": "cell-7b5374efd0e40c69",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Task 10 Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "akxkpCpWOKqU",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "110853de9aaaba37cb2fe601091b1e7d",
     "grade": true,
     "grade_id": "cell-94e04c938f3f5f84",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(model_cr, str), '`model_cr` should be type `str`.'\n",
    "assert all(term in model_cr for term in ['precision', 'recall', 'f1-score', 'support']), 'Is this a classification report?'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "40Fei4oXOKqU",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "00449a4317e9b4d383f2ca7d58a2b0af",
     "grade": false,
     "grade_id": "cell-d2b4843352d3085a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Task 11:** Using your best model, create a DataFrame `permutation_importances` with the model's permutation importances based on your validation data.\n",
    "\n",
    "- The index of the DataFrame should be your feature names.\n",
    "- The first column should be the mean importance.\n",
    "- The second column should be the importance standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "gtTc_kgkOKqU",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f8e984b2a5083b74b7eb0abec46f8d63",
     "grade": false,
     "grade_id": "cell-72936eec6980072b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''T11. Create DataFrame of permutation importances.'''\n",
    "# YOUR CODE HERE\n",
    "# permutation_importances = permutation_importance(model_boost, X_val, y_val, random_state=42)\n",
    "permutation_result = permutation_importance(model_boost, X_val, y_val, n_repeats=30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RZi2IWbY0ay3"
   },
   "outputs": [],
   "source": [
    "# data_perm = {'imp_mean':permutation_importances['importances_mean'],\n",
    "#              'imp_std':permutation_importances['importances_std']}\n",
    "# df_perm = pd.DataFrame(data_perm, index=X_val.columns).sort_values('imp_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "04VeHnfrAMnr"
   },
   "outputs": [],
   "source": [
    "permutation_importances = pd.DataFrame({\n",
    "    'mean_importance': permutation_result.importances_mean,\n",
    "    'importance_std': permutation_result.importances_std\n",
    "}, index=X_val.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V6QFfPkIABqH",
    "outputId": "2817af86-03a3-497a-f20e-1a4e563f8335"
   },
   "outputs": [],
   "source": [
    "permutation_importances.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TrKtN6bgzo18"
   },
   "outputs": [],
   "source": [
    "# permutation_importances = df_perm.drop(df_perm.index[-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "BkO_GTa52B-7",
    "outputId": "e403f598-4103-4cbd-9e88-aa7f7194b771"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'permutation_importances' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m permutation_importances\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'permutation_importances' is not defined"
     ]
    }
   ],
   "source": [
    "permutation_importances.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "8mSjZMOzOKqV",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dccb1015d0f5c2f8b23f780eb8e4abf7",
     "grade": false,
     "grade_id": "cell-9eb949d189e401bc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Task 11 Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "lV-h2ZpcOKqV",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d84e55cd6e77a52c576972ab68477c90",
     "grade": true,
     "grade_id": "cell-a4d8990e7070c2dd",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''Task 11 Test'''\n",
    "assert isinstance(permutation_importances, pd.DataFrame), '`permutation_importances` should be type `DataFrame`.'\n",
    "assert permutation_importances.shape == (7,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "m_t_zTOvOKqV",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f005618a5eb29cde9fbc73ab717b0e1c",
     "grade": false,
     "grade_id": "cell-3d8938c1715a596d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Task 12 (`stretch goal`):** Using your best model, create a PDP interaction plot to examine how `'Latitude'` and `'Longitude'` inform predictions. Remember to user your validation data.\n",
    "\n",
    "**Note:** Because of the way that `pdp_interact` works, it will throw an error if there are `NaN` values in your validation set. To avoid this problem, be sure to set `dataset` to `X_val.dropna()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "F7RtpobBOKqV",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ea5a8422d2efafe17ee63a77c5db1e41",
     "grade": false,
     "grade_id": "cell-224d3b408f9bdd88",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''T12. Create PDP interaction plot for \"Latitude\" and \"Longitude\".'''\n",
    "features = ['Longitude', 'Latitude']\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Using model_boost\n",
    "\n",
    "# Drop NaN values from the validation set\n",
    "# X_val_no_nan = X_val.dropna()\n",
    "\n",
    "# # Choose the features for the PDP interaction plot\n",
    "# features_to_plot = ['Latitude', 'Longitude']\n",
    "\n",
    "# # Create the PDP interaction plot\n",
    "# interaction_plot = pdp.PDPInteract(\n",
    "#     model_boost,\n",
    "#     dataset=X_val_no_nan,\n",
    "#     model_features=X_val_no_nan.columns,\n",
    "#     features=features_to_plot\n",
    "# )\n",
    "\n",
    "# # Display the PDP interaction plot\n",
    "# pdp.pdp_interact_plot(interaction_plot, features_to_plot)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "6o5ZrQxIOKqW",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0455e5a041c95c4c194165e5efb83538",
     "grade": false,
     "grade_id": "cell-60908df556f5057e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "What do you think? Is there a relationship between location and failing a food saftey inspection? Answer below.\n",
    "\n",
    "This task will not be autograded - but it is part of completing the challenge."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
